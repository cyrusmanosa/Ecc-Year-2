{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 tensorflowを使うためのモジュールをインストール"
      ],
      "metadata": {
        "id": "_axim_u3doVL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ltc26U_mDpJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ステップ:5 npzファイルを元に学習**"
      ],
      "metadata": {
        "id": "A0OhjW0DPHwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 学習用データの準備\n",
        "ローカルで作成したnpzファイルをクラウド上にアップロードした上で実行しましょう  \n",
        "【※注意】移動させて直後だとエラーが出る場合があるので、少しだけ間を置いてから再度実行してみてください"
      ],
      "metadata": {
        "id": "EVNuCxyQ85F7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWMGKAUmA-zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 データ前処理"
      ],
      "metadata": {
        "id": "Ys8q25dvBWmq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrBE4FzgBX5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 学習用とテスト用に分ける"
      ],
      "metadata": {
        "id": "TXWuOy0sCE1T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iw7JdP8UCIJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ステップ6: モデルの作成**"
      ],
      "metadata": {
        "id": "Fg028mvVPeAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 CNNのモデル作成"
      ],
      "metadata": {
        "id": "TrVcNjlZ9q7L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99GYKmJn9qgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 モデルのコンパイル"
      ],
      "metadata": {
        "id": "Wef9bZmkASy1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gdzeE-7AUo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 モデルの訓練"
      ],
      "metadata": {
        "id": "CK9SunSmAtuM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40AZLWTTAuz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **【課題1】：正解率がまだ少し低いですが、何が原因だと考えられますか？**"
      ],
      "metadata": {
        "id": "tcQnANDaHcCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 回答："
      ],
      "metadata": {
        "id": "dRnVVyXVHg59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ステップ:7 データの水増し**"
      ],
      "metadata": {
        "id": "hyP_c27-P9Be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 データの水増し　やり方の確認"
      ],
      "metadata": {
        "id": "-MC6_JXDKmrA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXvnILt3LEme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 水増しを踏まえた上で学習を行う"
      ],
      "metadata": {
        "id": "rl3VDfWQNITP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                   # 数学的な操作や配列を扱うためのモジュール\n",
        "from sklearn.model_selection import train_test_split  # データを分割するためのモジュール\n",
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models  # TensorFlowのライブラリをインポート\n",
        "import cv2\n",
        "\n",
        "# npzファイルから画像データを読み込む\n",
        "photos = np.load('photos.npz')\n",
        "# 画像データをxに代入\n",
        "x = photos['x']\n",
        "# ラベルデータをyに代入\n",
        "y = photos['y']\n",
        "\n",
        "\n",
        "# 画像の形状に関する情報\n",
        "im_rows = 128       # 画像の行数\n",
        "im_cols = 128       # 画像の列数\n",
        "im_color = 3       # 画像の色の数(RGBなので3)\n",
        "in_shape = (im_rows, im_cols, im_color)  # 画像の形状\n",
        "\n",
        "# 画像データを適切な形状に変換\n",
        "x = x.reshape(-1, im_rows, im_cols, im_color)\n",
        "# 画像の各ピクセルの値を0から1の範囲にするために255で割る\n",
        "x = x.astype('float32') / 255\n",
        "\n",
        "\n",
        "# データセットを訓練データとテストデータに分割\n",
        "# test_size=0.2は、全データのうち20%をテストデータとして使うことを意味する\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "\n",
        "######### 水増し処理 ##########\n",
        "\n",
        "\n",
        "######### 水増し処理 ##########\n",
        "\n",
        "\n",
        "# CNN（畳み込みニューラルネットワーク）モデルを作成します。これは、画像を理解するための強力なツールです。\n",
        "model = models.Sequential()\n",
        "\n",
        "# 最初の層：128個のフィルターを持つ畳み込み層を追加します。これは、画像の特徴（例：エッジ、テクスチャ）を検出します。\n",
        "# 3x3のサイズのフィルターを使用し、活性化関数としてReLU（ランプ関数）を使用します。\n",
        "# input_shape=(128, 128, 3)は、入力画像が128x128ピクセルで3つのカラーチャンネル（RGB）を持っていることを意味します。\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "\n",
        "# 次の層：2x2のサイズで最大プーリング層を追加します。これは、画像のサイズを半分にし、重要な特徴だけを残します。\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# 畳み込み層をもう一度追加しますが、今回は64個のフィルターを使用します。\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# もう一度、最大プーリング層を追加します。\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# 64個のフィルターを持つもう一つの畳み込み層を追加します。\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# ここで、画像を1Dのリストに変換します。これは、全結合層（デンスレイヤー）に入力するための前処理です。\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# 64個のノードを持つ全結合層（デンスレイヤー）を追加し、ReLU活性化関数を使用します。\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# 最終層：2個のノードを持つ全結合層を追加します。これは現時点で２種類の分類を行っているからです\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "# モデルを訓練する前の準備\n",
        "model.compile(\n",
        "    optimizer='adam',  # 最適化手法はAdam（これはパラメータの調整方法）\n",
        "    loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # 損失関数（予測と正解との差を計算）\n",
        "    metrics=['accuracy']  # 正解率を計算する（どれだけ予測が当たっているか）\n",
        ")\n",
        "\n",
        "\n",
        "# モデルを訓練する（学習させる）\n",
        "history = model.fit(\n",
        "    x_train, y_train,  # 訓練データ（画像）と正解ラベル\n",
        "\n",
        "    epochs=5,  # 全データを10回繰り返して学習する\n",
        "\n",
        "    # 検証データ（こちらは学習には使わない。学習の進行状況を確認するためだけに使用）\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "id": "NsK9AS0XNSYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 学習済みのモデルを保存"
      ],
      "metadata": {
        "id": "vkSec7rxhU0o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QYEjmSZhXZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成されたモデルのファイルをローカルにダウンロードしておきましょう。"
      ],
      "metadata": {
        "id": "wVTbVSNWACPj"
      }
    }
  ]
}